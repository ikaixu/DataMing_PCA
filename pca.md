# PCA实验 #
&emsp;&emsp;&emsp;&emsp;姓名:许楷&emsp;&emsp;学号:1120170488&emsp;&emsp;专业:数量经济学  
实验要求：  
1、基于PCA的人脸识别 （可设置不同的贡献率得出不同的主成分）  
2、研究训练样本及测试样本size对实验结果的影响  
3、PCA完成之后，对分类器的研究（最近邻，二阶，三阶，四阶等）  
4、比较实验结果，给出相关实验分析  
## 1. PCA人脸识别概论 ##
### 1.1实验过程 ###  
实验分为两个过程，一是训练模型过程，二是测试过程  
训练过程,计算特征脸  
测试过程,使用KNN近邻算法   
### 1.2代码详解 ###  
本次实验会使用python的numpy和matplotlib两个包，其中numpy这个包中提供了对矩阵运算的支持，而matplotlib这个包支持读取人脸图像数据。  
    #导入实验中使用库
    import numpy
    import matplotlib.image
#### 1.2.1 读取数据 ####
    allsamples = numpy.arange(10304).reshape(1,10304)#创建并初始化一个数组  
    for i in range(1,41):
        for j in range(1,6):
            a = matplotlib.image.imread('C:\\ORL\\s'+str(i)+'\\'+str(j)+'.jpg')
            #读取图像并转化为矩阵
            b = numpy.reshape(a, (1, -1), order='F')
            #矢量化，把所有数据排成一列，第二列接到第一列后面，以此类推。把得到的(N,1)数组转置为(1,N)
            b = b.astype(numpy.float64)
            #默认读取数据的数据类型为unit8，现在把它转化成float64
            allsamples = numpy.concatenate((allsamples, b), axis=0)
            #存入长度相同的数组中
    allsamples = numpy.delete(allsamples, 0, 0)#删去数组第一列
    allsamples = numpy.asmatrix(allsamples)#训练样本的数据矩阵
#### 1.2.2 PCA计算特征子空间
    samplemean = allsamples.mean(axis=0)#训练数据均值
    xmean = allsamples - samplemean#去中心化
    sigma = xmean*(xmean.T)#大矩阵转化成小矩阵
    v, d = numpy.linalg.eig(sigma)#求小矩阵的特征值特征向量,这一步中得到的特征值从大到小排序
    f = numpy.diag(v)#依次从大到小的特征值组成的对角数组
    g = numpy.asmatrix(f)#上述对角数组化为对角矩阵
    h = numpy.asmatrix(d)#特征向量数组化为矩阵
    #计算累计贡献率为0.9时的循环次数
    dsum = numpy.sum(v)#特征值求和
    dsum_extract = 0
    i = 0
    while((dsum_extract/dsum) < 0.9):
        dsum_extract = g[i,i]+dsum_extract
        i = i + 1
    base = (xmean.T) * h[:,0:(i-1)] * (numpy.diag(v[0:(i-1)] ** (-(1/2))))#解得基变换

    allcolor = allsamples * base#训练样本降维
#### 1.2.3 测试训练集(三阶近邻法)，输出样本识别率
    accu = 0
    for i in range(1,41):
        for j in range(6,11):
            a = matplotlib.image.imread('C：\\ORL\\s'+str(i)+'\\'+str(j)+'.jpg')
            b = numpy.reshape(a, (1, -1), order='F') #矢量化
            b = b.astype(numpy.float64)#数据类型转换
            tcoor = b * base#测试样本数据降维
            #三阶近邻
            mdist = numpy.arange(200.00).reshape(1,200)
            for k in range(0,200):
                mdist[0,k] = numpy.linalg.norm(tcoor - allcolor[k,:])
            mdist = numpy.argsort(mdist)
            lei1 = int((mdist[0,0] - 1)/5) + 1
            lei2 = int((mdist[0,1] - 1)/5) + 1
            lei3 = int((mdist[0,2] - 1)/5) + 1
            lei = 0
            if (lei1!=lei2 and lei2!=lei3):
                lei = lei1
            elif (lei1==lei2 and lei2!=lei3):
                lei = lei1
            elif (lei1!=lei2 and lei2==lei3):
                lei = lei2
            elif (lei1==lei3 and lei1!=lei2):
                lei = lei1
            else:
                lei = lei1
            if (lei == i):
                accu = accu + 1
    accurancy = accu / 200
### 1.3 实验研究中代码改变 ###
下面主要是说明此次实验中，研究内容对应的代码变化
+ 训练样本的变化，除了需要改变代码读取样本的部分,分类器中还需要做相应的修改
      lei1 = int((mdist[0,0] - 1)/5) + 1#这里除以5是因为训练的时候每5个样本作为一组
      lei2 = int((mdist[0,1] - 1)/5) + 1#要是改变样本大小这里的参数5也需要做相应的改变
      lei3 = int((mdist[0,2] - 1)/5) + 1
+ 贡献率
      dsum_extract = 0
      i = 0
      while((dsum_extract/dsum) < 0.9):#这里的参数0.9代表的就是贡献率，改变它会可以测试贡献率。
          dsum_extract = g[i,i]+dsum_extract
          i = i + 1  
+ 分类器  
        #三阶近邻
        mdist = numpy.arange(200.00).reshape(1,200)
        for k in range(0,200):
            mdist[0,k] = numpy.linalg.norm(tcoor - allcolor[k,:])
        mdist = numpy.argsort(mdist)
        #这里对应着分类器的改变
        lei1 = int((mdist[0,0] - 1)/5) + 1#这里采用了三阶近邻
        lei2 = int((mdist[0,1] - 1)/5) + 1
        lei3 = int((mdist[0,2] - 1)/5) + 1
        lei = 0
        if (lei1!=lei2 and lei2!=lei3):
            lei = lei1
        elif (lei1==lei2 and lei2!=lei3):
            lei = lei1
        elif (lei1!=lei2 and lei2==lei3):
            lei = lei2
        elif (lei1==lei3 and lei1!=lei2):
            lei = lei1
        else:
            lei = lei1
        if (lei == i):
            accu = accu + 1

## 2. 贡献率对实验的研究 ##
### 2.1 实验设计 ###
+ 保持实验中其他条件不变,训练样本和分类器默认不变化, 贡献率与准确率的关系  
  测试实验中的贡献率为0.57, 0.60, 0.63, 0.66, 0.69、0.72、0.75、0.78、0.81、0.84、0.87、0.90、0.93、0.96时，实验结果准确率
+ 改变实验的条件，观测实验条件改变的情况下，贡献率于准确率之间的关系是否稳定  
  第一个改变是，改变训练样本数目，这里拟从3变化到7，然后测试上述贡献率与准确率的关系。(保持默认分类器不改变)。  
  第二个改变是，改变分类器，k阶近邻，k从1变化到5。保持训练样本不改变。    

### 2.2 实验结果 ###
__2.2.1. 默认情况下,贡献率与测试结果准确率的关系__  

        #图像展示使用r的ggplot2包实现:  
        library("ggplot2")
        x <- c(0.57, 0.60, 0.63, 0.66, 0.69, 0.72, 0.75, 0.78, 0.81, 0.84, 0.87, 0.90, 0.93, 0.96)
        y <- c(0.74, 0.765, 0.765, 0.775, 0.80, 0.795, 0.84, 0.86, 0.86, 0.86, 0.87, 0.88, 0.875, 0.88)
        df1 <- data.frame(x,y)
        p <- ggplot(df1)
        p + geom_line(aes(x,y)) + labs(x = "贡献率", y = "准确率", caption = "训练样本为5,分类器为三阶近邻")

![1](./a1.png)  
+ _从该图像上可知:一般说来贡献率越高,预测结果的准确率也越高_  

__2.2.2 改变训练样本量时(分类器不变),贡献率与准确率的关系__  
![2](./a2.png)
+ _分类器不变的情况下,总体上来说,依然满足贡献率越高,预测结果的准确率越高_  
+ _在某些训练样本量情况下,预测结果准确率先随着方差贡献率增加而增加,增加到一定量后,再增加贡献率不会增加预测结果的准确率,反而可能会降低预测结果的准确率_  
+ _本实验中,训练样本量的大小是会影响方差贡献率与预测结果准确率之间关系的稳定性_  

__2.2.3 改变分类器时(训练样本量默认水平),贡献率与准确率的关系___
+ _1阶近邻分类器和二阶近邻分类器本质是相同的.在二阶近邻中当class1与class2不相同时,会判定为class1,因此无论如何都会判定样本为class1,从而与一阶近邻没有区别._  
+ _由于上述原因,这里研究一阶近邻,三阶近邻,四阶近邻和五阶近邻分类器_  
+ _注意:在四阶分类器中,如果诸如"class1==class2 && class3==class4 && class1~=class3"这种众数为2的情况时,都统一判定结果为class=class1_  
<table>
  <tr>
    <td>分类器\贡献率</td>
    <td>0.57</td>
    <td>0.60</td>
    <td>0.63</td>
    <td>0.66</td>
    <td>0.69</td>
    <td>0.72</td>
    <td>0.75</td>
    <td>0.78</td>
    <td>0.81</td>
    <td>0.84</td>
    <td>0.87</td>
    <td>0.90</td>
    <td>0.93</td>
    <td>0.96</td>
  </tr>
  <tr>
    <td>一阶近邻</td>
    <td>0.805</td>
    <td>0.84</td>
    <td>0.85</td>
    <td>0.845</td>
    <td>0.83</td>
    <td>0.855</td>
    <td>0.87</td>
    <td>0.88</td>
    <td>0.885</td>
    <td>0.89</td>
    <td>0.885</td>
    <td>0.885</td>
    <td>0.88</td>
    <td>0.89</td>
  </tr>
  <tr>
    <td>三阶近邻</td>
    <td>0.74</td>
    <td>0.765</td>
    <td>0.765</td>
    <td>0.775</td>
    <td>0.80</td>
    <td>0.795</td>
    <td>0.84</td>
    <td>0.86</td>
    <td>0.86</td>
    <td>0.86</td>
    <td>0.87</td>
    <td>0.88</td>
    <td>0.875</td>
    <td>0.88</td>
  </tr>
  <tr>
    <td>四阶近邻</td>
    <td>0.74</td>
    <td>0.79</td>
    <td>0.77</td>
    <td>0.775</td>
    <td>0.795</td>
    <td>0.81</td>
    <td>0.84</td>
    <td>0.855</td>
    <td>0.84</td>
    <td>0.855</td>
    <td>0.86</td>
    <td>0.86</td>
    <td>0.87</td>
    <td>0.88</td>
  </tr>
  <tr>
    <td>五阶近邻</td>
    <td>0.71</td>
    <td>0.70</td>
    <td>0.685</td>
    <td>0.685</td>
    <td>0.735</td>
    <td>0.755</td>
    <td>0.75</td>
    <td>0.78</td>
    <td>0.79</td>
    <td>0.78</td>
    <td>0.765</td>
    <td>0.765</td>
    <td>0.74</td>
    <td>0.79</td>
  </tr>
</table>
+ __结论 :__ 从上表中的数据,依旧可以得出这样的结论:一定范围内,随着贡献率的增加与准确率也会增加;贡献率增加到一定量时,准确率会稳定在一个水平,表现出上下波动.我们还发现,分类器对该规律的稳定性有一定影响,例如五阶近邻的情况下就表现得不明显.  
### 2.3实验结论 ###
+ __一定范围内,随着贡献率的增加与准确率也会增加;贡献率增加到一定量时,准确率会稳定在一个水平,表现出上下波动.__  
+ __该结论受到训练样本量和分类器的影响,但这种影响并不改变上述趋势__

## 3. 训练样本和测试样本对实验结果的影响 ##
### 3.1 实验设计 ###  
+ 默认条件下，样本量对结果准确率的影响
+ 改变实验条件，看样本对实验结果准确率关系是否稳定  
先改变贡献率(固定分类器),再改变分类器(固定贡献率)

### 3.2 实验结果 ###
__3.2.1 默认条件下,样本量与测试结果准确率的关系__  

![3](./a3.bmp)  

+ 显然,训练样本量越多,测试结果越准确  

__3.2.2 分类器不变,贡献率的变化如何影响训练样本量与测试结果准确率的关系__  

![](./a4.png)  
+ _显然,随着训练样本增多,测试结果准确率是提高的_
+ _贡献率的不同,并不影响这一结论_  

__3.2.4 贡献率不变(默认0.9),分类器器变化如何影响训练样本量与测试结果准确率的关系__  
<table>
  <tr>
    <td></td>
    <td>3</td>
    <td>4</td>
    <td>5</td>
    <td>6</td>
    <td>7</td>
  </tr>
  <tr>
    <td>一阶近邻</td>
    <td>0.84386</td>
    <td>0.87083</td>
    <td>0.885</td>
    <td>0.95625</td>
    <td>0.96667</td>
  </tr>
  <tr>
    <td>三阶近邻</td>
    <td>0.78214</td>
    <td>0.83750</td>
    <td>0.88</td>
    <td>0.90625</td>
    <td>0.94167</td>
  </tr>
  <tr>
    <td>四阶近邻</td>
    <td>0.625</td>
    <td>0.72083</td>
    <td>0.86</td>
    <td>0.913250</td>
    <td>0.94167</td>
  </tr>
  <tr>
    <td>五阶近邻</td>
    <td>0.6750</td>
    <td>0.74167</td>
    <td>0.765</td>
    <td>0.8750</td>
    <td>0.91667</td>
  </tr>  
</table>
+ 从上表中可以看出,无论分类器是怎么样的,训练样本量越多则预测结果准确率越高.
+ 也说明,分类器对该规律的稳定性基本没有影响  

### 3.3 实验结论 ###
__训练样本量越多则预测结果准确率越高,且该规律比较稳定,并不会受分类器和贡献率的影响.__


## 4. 分类器的研究 ##

### 4.1 实验设计 ###
+ 默认条件下，分类器对实验结果的影响
+ 改变实验条件，看分类器对实验结果的影响的关系是否稳定


### 4.2 实验结果 ###

+ 由前面的研究和容易得到一些关于分类器的结论
+ 现在用图形展示上面两个关于分类器的图表
+ 首先,在不同贡献率的情况下,看分类器与预测结果准确率的关系  
![](./a5.bmp)
+ _图像表明:本实验中,一阶近邻分类器在任意贡献率水平上,分类准确度都高于其他分类器;五阶近邻分类器,在任意贡献率水平上,分类准确度都低于其他分类器;三阶近邻分类器与四阶近邻分类器,分类准确度比较接近_  
+ 下面,在不同样本量水平下,看分类器与预测结果准确率的关系  
![](./a6.bmp)  
+ _该图像表明:本实验中,一阶近邻分类器在任意样本容量水平上,分类准确率高于其他分类器;其他分类器与分类准确率之间的关系则并不明朗_  
### 4.3 实验结论 ###
__通过上述分析知:本实验中,一阶近邻分类器的分类效果最好,而五阶近邻分类器的分类效果比较不理想,三阶近邻分类器和四阶近邻分类器的分类效果比较接近,次于一阶近邻分类器的分类效果,优于五阶近邻分类器的分类效果__
